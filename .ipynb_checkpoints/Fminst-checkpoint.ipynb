{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import nan\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fminsttrain= pd.read_csv(r'C:\\Users\\avida\\Downloads\\archive (7)\\fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=fminsttrain['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fminsttrain.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        9\n",
       "2        6\n",
       "3        0\n",
       "4        3\n",
       "        ..\n",
       "59995    9\n",
       "59996    1\n",
       "59997    8\n",
       "59998    8\n",
       "59999    7\n",
       "Name: label, Length: 60000, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fminsttrain['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        9\n",
       "2        6\n",
       "3        0\n",
       "4        3\n",
       "        ..\n",
       "59995    9\n",
       "59996    1\n",
       "59997    8\n",
       "59998    8\n",
       "59999    7\n",
       "Name: label, Length: 60000, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = fminsttrain['label']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       5       0   \n",
       "3           0       0       0       1       2       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       0       0       0       0       0       0       0       0       0   \n",
       "59996       0       0       0       0       0       0       0       0       0   \n",
       "59997       0       0       0       0       0       0       0       0       0   \n",
       "59998       0       0       0       0       0       0       0       0       0   \n",
       "59999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         0         0   \n",
       "2            0  ...         0         0         0        30        43   \n",
       "3            0  ...         3         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "59995        0  ...         0         0         0         0         0   \n",
       "59996        0  ...        73         0         0         0         0   \n",
       "59997        0  ...       160       162       163       135        94   \n",
       "59998        0  ...         0         0         0         0         0   \n",
       "59999        0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train= fminsttrain.drop(['label'],axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = pd.DataFrame(scale.fit_transform(X_train.values), columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>0.198798</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>0.275910</td>\n",
       "      <td>0.389449</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>0.366132</td>\n",
       "      <td>0.406799</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549579</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.374570</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666865</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>2.178732</td>\n",
       "      <td>2.839056</td>\n",
       "      <td>3.487716</td>\n",
       "      <td>2.664137</td>\n",
       "      <td>1.373435</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.022693</td>\n",
       "      <td>-0.028907</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.057575</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>-0.098084</td>\n",
       "      <td>-0.155981</td>\n",
       "      <td>-0.238546</td>\n",
       "      <td>-0.377959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601712</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>-0.406441</td>\n",
       "      <td>-0.440185</td>\n",
       "      <td>-0.396719</td>\n",
       "      <td>-0.287717</td>\n",
       "      <td>-0.158258</td>\n",
       "      <td>-0.091432</td>\n",
       "      <td>-0.033046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
       "0     -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "1     -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "2     -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "3     -0.009505 -0.022693 -0.028907  0.366132  0.406799 -0.070503 -0.098084   \n",
       "4     -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59995 -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "59996 -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "59997 -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "59998 -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "59999 -0.009505 -0.022693 -0.028907 -0.041557 -0.057575 -0.070503 -0.098084   \n",
       "\n",
       "         pixel8    pixel9   pixel10  ...  pixel775  pixel776  pixel777  \\\n",
       "0     -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "1     -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "2      0.198798 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "3     -0.155981 -0.238546 -0.377959  ... -0.549579 -0.476945 -0.395154   \n",
       "4     -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "59995 -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "59996 -0.155981 -0.238546 -0.377959  ...  0.666865 -0.476945 -0.395154   \n",
       "59997 -0.155981 -0.238546 -0.377959  ...  2.178732  2.839056  3.487716   \n",
       "59998 -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "59999 -0.155981 -0.238546 -0.377959  ... -0.601712 -0.476945 -0.395154   \n",
       "\n",
       "       pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0     -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "1     -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "2      0.275910  0.389449 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "3     -0.406441 -0.440185 -0.374570 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "4     -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "59995 -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "59996 -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "59997  2.664137  1.373435 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "59998 -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "59999 -0.406441 -0.440185 -0.396719 -0.287717 -0.158258 -0.091432 -0.033046  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c234065bb0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.85)\n",
    "train_pca =pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA1 = pd.DataFrame(train_pca)\n",
    "X_test_PCA1 = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 81)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score: 0.8801666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1232\n",
      "           1       0.99      0.97      0.98      1174\n",
      "           2       0.80      0.82      0.81      1200\n",
      "           3       0.88      0.90      0.89      1242\n",
      "           4       0.79      0.81      0.80      1185\n",
      "           5       0.95      0.95      0.95      1141\n",
      "           6       0.71      0.66      0.69      1243\n",
      "           7       0.94      0.95      0.94      1224\n",
      "           8       0.96      0.98      0.97      1149\n",
      "           9       0.95      0.95      0.95      1210\n",
      "\n",
      "    accuracy                           0.88     12000\n",
      "   macro avg       0.88      0.88      0.88     12000\n",
      "weighted avg       0.88      0.88      0.88     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgboost.XGBClassifier(n_estimators = 150,n_jobs = -1,learning_rate = 0.5, seed = 0,eval_metric='mlogloss',use_label_encoder=False)\n",
    "xgb_reg.fit(X_train_PCA1, y_train)\n",
    "y_train_xgb_reg = xgb_reg.predict(X_train_PCA1)\n",
    "y_pred_xgb_reg = xgb_reg.predict(X_test_PCA1)\n",
    "xgb_reg_train = metrics.accuracy_score(y_train,y_train_xgb_reg)\n",
    "xgb_reg_accuracy = metrics.accuracy_score(y_val, y_pred_xgb_reg)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy score: {}\".format(xgb_reg_accuracy))\n",
    "print(metrics.classification_report(y_val, y_pred_xgb_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(criterion='entropy', max_depth=70, n_estimators=100)\n",
    "random_forest.fit(X_train_PCA1, y_train)\n",
    "y_train_forest = random_forest.predict(X_train_PCA1)\n",
    "y_pred_forest = random_forest.predict(X_test_pca)\n",
    "random_forest_train = metrics.accuracy_score(y_train,y_train_forest)\n",
    "random_forest_accuracy = metrics.accuracy_score(y_val, y_pred_forest)\n",
    "\n",
    "print(\"Test Accuracy score: {}\".format(random_forest_accuracy))\n",
    "print(metrics.classification_report(y_val, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_PCA1,y_train)\n",
    "y_pred = gnb.predict(X_test_PCA1)\n",
    "label, count = np.unique(np.array(y_pred), return_counts=True)\n",
    "print(\"Test Accuracy score: {}\".format(metrics.accuracy_score(y_val, y_pred)))\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_PCA1,y_train)\n",
    "y_pred_logistic= clf.predict(X_test_PCA1)\n",
    "print(\"Test Accuracy score: {}\".format(metrics.accuracy_score(y_val, y_pred_logistic)))\n",
    "print(metrics.classification_report(y_val, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            eval_metric='mlogloss', gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.5,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=150, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None, seed=0,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            use_label_encoder=False,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 150,n_jobs = -1,learning_rate = 0.5, seed = 0,eval_metric='mlogloss',use_label_encoder=False)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf),('xgb', xgb_clf)],\n",
    "    voting='soft',n_jobs=-1)\n",
    "voting_clf.fit(X_train_PCA1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.83475\n",
      "RandomForestClassifier 0.8659166666666667\n",
      "XGBClassifier 0.8801666666666667\n",
      "VotingClassifier 0.88\n"
     ]
    }
   ],
   "source": [
    "for clf in( log_clf, rnd_clf, xgb_clf,voting_clf):\n",
    "    clf.fit(X_train_PCA1,y_train)\n",
    "    y_pred_clf=clf.predict(X_test_PCA1)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_val,y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators = 150,n_jobs = -1,learning_rate = 0.5, seed = 0,eval_metric='mlogloss',use_label_encoder=False)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf),('xgb', xgb_clf)],\n",
    "    voting='hard',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Test set\n",
      "- Accuracy: 0.87625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimator_list = [\n",
    "    ('xgb_clf',xgb_clf),\n",
    "    ('rnd_clf',rnd_clf),\n",
    "    ('voting_clf',voting_clf),\n",
    "    ('log_clf',log_clf),]\n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list, final_estimator=xgboost.XGBClassifier(n_estimators = 150,n_jobs = -1,learning_rate = 0.5, seed = 0,eval_metric='mlogloss',use_label_encoder=False)\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stack_model.fit(X_train_PCA1,y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train_PCA1)\n",
    "y_test_pred = stack_model.predict(X_test_PCA1)\n",
    "\n",
    "\n",
    "# Test set model performance\n",
    "stack_model_test_accuracy = accuracy_score(y_val, y_test_pred) # Calculate Accuracy\n",
    "\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaggingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd04cc646bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m bag_clf = BaggingClassifier(\n\u001b[0m\u001b[0;32m      2\u001b[0m StackingClassifier(n_jobs=-1,estimators=estimator_list, final_estimator=LogisticRegression()),bootstrap=True)\n\u001b[0;32m      3\u001b[0m \u001b[0mbag_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_PCA1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_bagging\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbag_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_PCA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy score: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_bagging\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaggingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "StackingClassifier(n_jobs=-1,estimators=estimator_list, final_estimator=LogisticRegression()),bootstrap=True)\n",
    "bag_clf.fit(X_train_PCA1,y_train)\n",
    "y_pred_bagging= bag_clf.predict(X_test_PCA1)\n",
    "print(\"Test Accuracy score: {}\".format(metrics.accuracy_score(y_val, y_pred_bagging)))\n",
    "print(metrics.classification_report(y_val, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasting_clf = BaggingClassifier(\n",
    "StackingClassifier(n_jobs=-1,estimators=estimator_list, final_estimator=LogisticRegression())bootstrap=False)\n",
    "pasting_clf.fit(X_train_PCA1,y_train)\n",
    "y_pred_pasting= pasting_clf.predict(X_test_PCA1)\n",
    "print(\"Test Accuracy score: {}\".format(metrics.accuracy_score(y_val, y_pred_pasting)))\n",
    "print(metrics.classification_report(y_val, y_pred_pasting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
